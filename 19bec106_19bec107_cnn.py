# -*- coding: utf-8 -*-
"""19bec106_19bec107_CNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BzndR9tldYwz0lmyL6h0ua4v6Asy0m4l
"""

import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow import keras
from keras import Sequential
from keras.layers import Dense,Activation,MaxPooling2D,Flatten,BatchNormalization,Conv2D,Input
from keras.utils.np_utils import to_categorical
from keras.callbacks import ReduceLROnPlateau
from keras.preprocessing.image import ImageDataGenerator
from sklearn.model_selection import train_test_split
from keras import Model

from google.colab import drive
drive.mount('/content/drive')

train=pd.read_csv('/content/drive/MyDrive/HandwrittenDigit/train.csv', header='infer').values
X_test=pd.read_csv('/content/drive/MyDrive/HandwrittenDigit/test.csv', header='infer').values

X_train=train[:,1:]
y_train=train[:,0]

X_train=(X_train.astype(np.float32)-127.5)/255
X_test=(X_test.astype(np.float32)-127.5)/255

print(X_train)

X_train=X_train.reshape(-1,28,28,1)
X_test=X_test.reshape(-1,28,28,1)

y_train=to_categorical(y_train)

X_train, X_val, y_train, y_val= train_test_split(X_train, y_train, test_size=0.2, random_state=2)

cnn=Sequential()
input=Input(X_train.shape[1:])
l1=Conv2D(32,kernel_size=(3,3),strides=(1,1),padding='Valid',activation=None,use_bias=False)(input)
b1=BatchNormalization()(l1)
a1=Activation('relu')(b1)

l2=Conv2D(64,kernel_size=(3,3),strides=(1,1),padding='Valid',activation=None,use_bias=False)(a1)
b2=BatchNormalization()(l2)
a2=Activation('relu')(b2)
m1=MaxPooling2D((2,2))(a2)

l3=Conv2D(96,kernel_size=(3,3),strides=(1,1),padding='Valid',activation=None,use_bias=False)(m1)
b3=BatchNormalization()(l3)
a3=Activation('relu')(b3)

l4=Conv2D(128,kernel_size=(3,3),strides=(1,1),padding='Valid',activation=None,use_bias=False)(a3)
b4=BatchNormalization()(l4)
a5=Activation('relu')(b4)

f=Flatten()(a5)
out=Dense(units=10)(f)
b5=BatchNormalization()(out)
a5=Activation('softmax')(b5)

model=Model(input,a5)
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

train_datagen = ImageDataGenerator(featurewise_center=False,
                             samplewise_center=False,
                             featurewise_std_normalization=False,
                             samplewise_std_normalization=False,
                             zca_whitening=False,
                             rotation_range=10,
                             zoom_range=0.1,
                             width_shift_range=0.1,
                             height_shift_range=0.1,
                             horizontal_flip=False,
                             vertical_flip=False
                            )

train_generator = train_datagen.flow(X_train, y_train,
                                     batch_size=120,
                                     shuffle=True)

val_datagen = ImageDataGenerator()
val_generator = val_datagen.flow(X_val, y_val,
                                 batch_size=120,
                                 shuffle=True)

reduceLROnPlateau = ReduceLROnPlateau(monitor='val_acc', 
                                patience=3,
                                verbose=1, 
                                factor=0.1,
                                min_lr=0.00001)

model.summary()

tf.keras.utils.plot_model(model)

model.fit(
    train_generator,
    epochs=10,
    callbacks=[reduceLROnPlateau], 
    validation_data=val_generator,
)

results = model.predict(X_test)
results = np.argmax(results,axis = 1)
results = pd.Series(results,name="Label")

submission = pd.concat([pd.Series(range(1,28001),name = "ImageId"),results],axis = 1)
submission.to_csv("/content/drive/MyDrive/HandwrittenDigit/submission.csv",index=False)